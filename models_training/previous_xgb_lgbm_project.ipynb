{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87746ffc",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV, cross_val_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\__init__.py:25\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     IS64,\n\u001b[0;32m     19\u001b[0m     PY39,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     PYPY,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     is_numpy_dev,\n\u001b[0;32m     27\u001b[0m     np_version_under1p21,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     33\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_function_name\u001b[39m(f: F, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m F:\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Appender,\n\u001b[0;32m      4\u001b[0m     Substitution,\n\u001b[0;32m      5\u001b[0m     cache_readonly,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     hash_array,\n\u001b[0;32m     10\u001b[0m     hash_pandas_object,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[0;32m      8\u001b[0m     Callable,\n\u001b[0;32m      9\u001b[0m     Mapping,\n\u001b[0;32m     10\u001b[0m     cast,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     F,\n\u001b[0;32m     17\u001b[0m     T,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     NaT,\n\u001b[0;32m     16\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     iNaT,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kusha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('encoded_bankruptcy_data.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f3ed2-54b3-443a-a947-09c93af9fb55",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091343a-bbfe-456e-bb1e-1e99a45ff583",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(['company_name', 'Bankruptcy_Status'], axis=1)\n",
    "y = df['Bankruptcy_Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTrain target distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"Test target distribution:\\n{y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764512db-6281-4bfc-9371-f948cddf37c9",
   "metadata": {},
   "source": [
    "## FEATURE ENGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3e395-bead-48b4-a7a1-1c98bc1aaf47",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nScaled train set - Mean: {X_train_scaled.mean():.6f}, Std: {X_train_scaled.std():.6f}\")\n",
    "print(f\"Scaled test set - Mean: {X_test_scaled.mean():.6f}, Std: {X_test_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc5c10-3281-4dca-b370-ca4e603bb37b",
   "metadata": {},
   "source": [
    "## OPTIMIZATION FOR IMBALANCED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e2dfc-b680-4daf-bae3-e271642161d9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Handle imbalance using scale_pos_weight for XGBoost and class_weight for LightGBM\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "print(f\"\\nClass imbalance ratio (scale_pos_weight): {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570c951-a9c1-4e49-8e60-ac7bfc1cdb90",
   "metadata": {},
   "source": [
    "## XGBOOST MODEL TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca55c0-cd81-417e-9bc3-c76e455b131b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# XGBoost: GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    tree_method='hist'  # Faster training\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]  # Added to prevent overfitting\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nFitting the XGBoost model using GridSearchCV......\")\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb, xgb_params, cv=5, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "xgb_grid.fit(X_train_scaled, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "\n",
    "print(f\"\\nBest XGBoost params: {xgb_grid.best_params_}\")\n",
    "print(f\"Best XGBoost CV F1 score: {xgb_grid.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578ee8b5-b0a7-449e-8b91-7d88dd65e615",
   "metadata": {},
   "source": [
    "## LightGBM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26ef1d-d512-4ad0-ac4c-3e4a0feb52ec",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# LightGBM: GridSearchCV\n",
    "lgbm = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    force_col_wise=True,  # Fix for auto-choosing warnings\n",
    "    verbose=-1,  # Suppress iteration logs\n",
    "    min_child_samples=20,  # Prevent overfitting\n",
    "    min_data_in_leaf=20\n",
    ")\n",
    "\n",
    "lgbm_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [15, 31, 50],  # Adjusted range\n",
    "    'min_child_samples': [20, 30, 40],  # Added\n",
    "    'feature_fraction': [0.8, 0.9, 1.0]  # Added for regularization\n",
    "}\n",
    "\n",
    "lgbm_grid = GridSearchCV(\n",
    "    lgbm, lgbm_params, cv=5, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFitting LightGBM GridSearchCV...\")\n",
    "lgbm_grid.fit(X_train_scaled, y_train)\n",
    "lgbm_best = lgbm_grid.best_estimator_\n",
    "\n",
    "print(f\"\\nBest LightGBM params: {lgbm_grid.best_params_}\")\n",
    "print(f\"Best LightGBM CV F1 score: {lgbm_grid.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb752a-957f-43cd-842d-37cbbb8331cb",
   "metadata": {},
   "source": [
    "## Cross Validation (Metric => F1-Score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381961a-88c7-46fe-9186-7b908200dbac",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation scores\n",
    "xgb_cv_f1 = cross_val_score(xgb_best, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "lgbm_cv_f1 = cross_val_score(lgbm_best, X_train_scaled, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"\\nXGBoost CV F1: {xgb_cv_f1.mean():.4f} (+/- {xgb_cv_f1.std() * 2:.4f})\")\n",
    "print(f\"LightGBM CV F1: {lgbm_cv_f1.mean():.4f} (+/- {lgbm_cv_f1.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d5ca8-e810-4d0c-80c0-6038b2eb8540",
   "metadata": {},
   "source": [
    "## CHECKING THE MODELS ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce51db0",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "\n",
    "def evaluate(model, X_test, y_test, model_name):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{model_name} TEST SET EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nAccuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "evaluate(xgb_best, X_test_scaled, y_test, \"XGBOOST\")\n",
    "evaluate(lgbm_best, X_test_scaled, y_test, \"LIGHTGBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d01454-9f1e-48fd-8f39-0f35b85cb145",
   "metadata": {},
   "source": [
    "## SAVING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264210f-d05b-4448-aa7f-396730711de2",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save both trained models\n",
    "joblib.dump(xgb_best, \"xgb_best_model.pkl\")\n",
    "joblib.dump(lgbm_best, \"lgbm_best_model.pkl\")\n",
    "\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e546b65-724d-48ac-b8c1-503958100c66",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the trained models\n",
    "xgb_best = joblib.load(\"xgb_best_model.pkl\")\n",
    "lgbm_best = joblib.load(\"lgbm_best_model.pkl\")\n",
    "\n",
    "print(\"Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e335f",
   "metadata": {},
   "source": [
    "## FEATURE IMPORTANCE BY CALCULATING INFORMATION GAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f89d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Calculate Information Gain (Mutual Information) for each feature\n",
    "print(\"INFORMATION GAIN (MUTUAL INFORMATION) ANALYSIS\")\n",
    "\n",
    "\n",
    "# Use the original training data for information gain calculation\n",
    "info_gain = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
    "\n",
    "# Create DataFrame with feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Information_Gain': info_gain\n",
    "}).sort_values('Information_Gain', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features by Information Gain:\")\n",
    "print(feature_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nAll Features Information Gain:\")\n",
    "print(feature_importance_df.to_string(index=False))\n",
    "\n",
    "# Save feature importance\n",
    "joblib.dump(feature_importance_df, \"feature_importance.pkl\")\n",
    "print(\"\\nFeature importance saved to 'feature_importance.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052862ac",
   "metadata": {},
   "source": [
    "## Trying SMOTE for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SMOTE RESAMPLING ANALYSIS\")\n",
    "\n",
    "print(f\"\\nOriginal Training Set Distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Class 0: {y_train.value_counts()[0]} samples\")\n",
    "print(f\"Class 1: {y_train.value_counts()[1]} samples\")\n",
    "print(f\"Imbalance Ratio: {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nAfter SMOTE Resampling:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())\n",
    "print(f\"Class 0: {pd.Series(y_train_resampled).value_counts()[0]} samples\")\n",
    "print(f\"Class 1: {pd.Series(y_train_resampled).value_counts()[1]} samples\")\n",
    "print(f\"Total samples increased from {len(y_train)} to {len(y_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70cb5f7",
   "metadata": {},
   "source": [
    "## Evaluate loaded models on SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EVALUATING PRE-TRAINED MODELS ON SMOTE DATA\")\n",
    "\n",
    "def evaluate_on_smote(model, X_resampled, y_resampled, X_test, y_test, model_name):\n",
    "    print(f\"\\n{model_name} - Training Set (SMOTE) Evaluation:\")\n",
    "    y_train_pred = model.predict(X_resampled)\n",
    "    print(f\"Accuracy:  {accuracy_score(y_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_resampled, y_train_pred, zero_division=0):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_resampled, y_train_pred, zero_division=0):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_resampled, y_train_pred, zero_division=0):.4f}\")\n",
    "    \n",
    "    print(f\"\\n{model_name} - Test Set Evaluation:\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy:  {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_test, y_test_pred, zero_division=0):.4f}\")\n",
    "\n",
    "evaluate_on_smote(xgb_best, X_train_resampled, y_train_resampled, \n",
    "                  X_test_scaled, y_test, \"XGBoost\")\n",
    "evaluate_on_smote(lgbm_best, X_train_resampled, y_train_resampled, \n",
    "                  X_test_scaled, y_test, \"LightGBM\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8622898,
     "sourceId": 13573749,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
